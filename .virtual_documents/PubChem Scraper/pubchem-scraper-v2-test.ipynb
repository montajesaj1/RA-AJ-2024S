


import selenium 
import csv
import re
import pandas as pd

from selenium import webdriver
from selenium.webdriver.common.keys import Keys
from selenium.webdriver.common.by import By
from selenium.webdriver.chrome.service import Service
from webdriver_manager.chrome import ChromeDriverManager
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.common.exceptions import NoSuchElementException, TimeoutException
from selenium.webdriver.chrome.options import Options

import time





# molecules_df = pd.read_excel('data.xlsx', sheet_name = 'in')
# molecules_arr = molecules_df['molecule'].tolist()

# pattern = re.compile(r'(\d)-(\d)')
# pattern2 = re.compile(r'_')
# pattern3 = re.compile(r'(\d)-([a-zA-Z])')

# # List to store updated molecule names
# updated_molecules_arr = []

# for molecule in molecules_arr:
#     updated_molecule = pattern.sub(r'\1,\2', molecule)
#     updated_molecule = pattern2.sub(r' ', updated_molecule)
#     updated_molecule = pattern3.sub(r'\1 \2', updated_molecule)
#     updated_molecules_arr.append(updated_molecule)

# updated_molecules_df = pd.DataFrame(updated_molecules_arr, columns=['updated_molecule'])
# updated_molecules_df

updated_molecules_arr = ['ACETYLCYSTEINE', 'CYSTEINE', 'CYSTINE', 'DASATINIB', 'DEFIBROTIDE', 'TYLOSIN', 'AMFETAMINE', 'AMPHETAMINE', 'CHROMIUM', 'COUGH AND COLD PREPARATIONS', 'FIXATIVES', 'GLUCOSE', 'UREA', 'BENZALKONIUM CHLORIDE', 'BENZYL ALCOHOL', '2 PROPANOL', 'ACETIC ACID', 'ANTACIDS', 'ASPARTIC ACID', 'AXITINIB', 'AZTREONAM', 'BABY LOTION']





def get_pubchem_url(chemical):
    return f'https://pubchem.ncbi.nlm.nih.gov/#query={chemical}'

def setup_webdriver():
    chrome_options = Options()
    chrome_options.add_argument("--headless")
    service = Service(ChromeDriverManager().install())
    driver = webdriver.Chrome(service=service, options=chrome_options)
    return driver

def get_best_match(molecule, driver):
    url = "N/A"  # Default in case of failure
    result_type = "Not Found"  # Default result type

    driver.get(get_pubchem_url(molecule))
    try:
        WebDriverWait(driver, 3).until(EC.visibility_of_element_located((By.CSS_SELECTOR, 'a[data-action="featured-result-link"], a[data-action="result-link"]')))
        elements = driver.find_elements(By.CSS_SELECTOR, 'a[data-action="featured-result-link"], a[data-action="result-link"]')
        if elements:
            element = elements[0]
            url = element.get_attribute('href')
            action = element.get_attribute('data-action')
            if action == 'featured-result-link':
                result_type = 'FEATURED'
            else:
                result_type = 'RELEVANT'
    except (NoSuchElementException, TimeoutException):
        pass  # URL remains "N/A" and result_type remains "Not Found" if no match is found or if there's a timeout

    return molecule, url, result_type

def get_best_matches(parsed_molecules):
    best_matches = []
    driver = setup_webdriver()  # Initialize the WebDriver once
    try:
        for parsed_molecule in parsed_molecules:
            molecule, url, result_type = get_best_match(parsed_molecule, driver)
            best_matches.append((molecule, url, result_type))
    finally:
        driver.quit()  # Make sure to quit the WebDriver

    return best_matches


best_matches = get_best_matches(updated_molecules_arr)


df = pd.DataFrame(best_matches, columns=['Molecule', 'Link', 'Result Type'])


df


# df_merged = pd.concat([molecules_df, df], ignore_index=True, sort=False, axis=1)
df_merged = df
df_merged.columns = ['Parsed', 'Link', 'Result Type']
df_merged


# df_merged_csv = df_merged.to_csv('FINAL_MOLECULE_LINKS.csv', index = False) 


links_arr = df_merged["Link"].tolist()
links_arr





def get_cas_numbers(link, driver):
    cas_numbers = {"CAS": "N/A", "Deprecated CAS": "N/A"}  # Default in case of failure

    try:
        driver.get(link)
        # Wait and locate the CAS number section
        try:
            cas_elements = WebDriverWait(driver, 6).until(EC.visibility_of_all_elements_located((By.CSS_SELECTOR, 'section#CAS div.break-words')))
            cas_numbers["CAS"] = ', '.join([el.text.strip() for el in cas_elements])
        except (NoSuchElementException, TimeoutException):
            cas_numbers["CAS"] = "N/A"  # CAS number not found

        # Wait and locate the Deprecated CAS number section, if present
        try:
            deprecated_cas_elements = driver.find_elements(By.CSS_SELECTOR, 'section#Deprecated-CAS div.break-words')
            # deprecated_cas_elements = WebDriverWait(driver, 3).until(EC.visibility_of_all_elements_located((By.CSS_SELECTOR, 'section#Deprecated-CAS div.break-words')))
            cas_numbers["Deprecated CAS"] = ', '.join([el.text.strip() for el in deprecated_cas_elements])
            
        except (NoSuchElementException, TimeoutException):
            cas_numbers["Deprecated CAS"] = "N/A"  # Deprecated CAS number not found
            
    except Exception as e:
        print(f"Error retrieving CAS numbers for {link}: {e}")

    return cas_numbers

def get_cas_numbers_concurrently(links):
    cas_matches = []
    driver = setup_webdriver()  # Initialize the WebDriver once

    try:
        for link in links:
            cas_matches.append(get_cas_numbers(link, driver))

    finally:
        driver.quit()  # Make sure to quit the WebDriver

    return cas_matches      


cas_numbers = get_cas_numbers_concurrently(links_arr)


df_cas = pd.DataFrame(cas_numbers, columns=['CAS', 'Deprecated CAS'])
df_cas





final_df = pd.concat([df_merged, df_cas], ignore_index=True, sort=False, axis=1)


final_df


final_df.to_csv("test.csv", index=False)


final_df.columns=['Original Molecule', 'Parsed Molecule', 'Link', 'Result Type', 'CAS', 'Deprecated CAS']





final_df['Compound/Substance'] = final_df['Link'].apply(lambda x: 'COMPOUND' if 'compound' in str(x) else ('SUBSTANCE' if 'substance' in str(x) else 'N/A'))


final_df


final_df['Original Molecule'] = final_df['Parsed Molecule']
final_df = final_df[['Original Molecule', 'Parsed Molecule', 'Link', 'Result Type', 'CAS', 'Deprecated CAS', 'Compound/Substance']]
final_df





final_df_csv = final_df.to_csv('scraped_pubchem_data_corrected.csv', index = False) 



