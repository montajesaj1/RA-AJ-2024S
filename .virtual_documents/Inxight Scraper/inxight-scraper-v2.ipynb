import csv
import re
import pandas as pd
import time

import selenium 
from selenium import webdriver
from selenium.webdriver.common.keys import Keys
from selenium.webdriver.common.by import By
from selenium.webdriver.chrome.service import Service
from webdriver_manager.chrome import ChromeDriverManager
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.common.exceptions import NoSuchElementException, TimeoutException
from selenium.webdriver.chrome.options import Options


sample_df = pd.read_csv("PUBCHEM_SYNONYMS_FLAGGED.csv")
# sample_df = sample_df.head(60)
cas_df = sample_df[sample_df["CAS"] != "No CAS info"]
missing_df = sample_df[sample_df["CAS"] == "No CAS info"] 


cas_df = cas_df[['Parsed Molecule', 'CAS']]
missing_df = missing_df[['Parsed Molecule', 'CAS']]


def get_first_cas(cas_string):
    # Replace all semicolons with commas
    modified_string = re.sub(r';', ',', cas_string)
    
    if modified_string == "No CAS info":
        return None
    
    return modified_string.split(',')[0].strip()

# Apply this function to the entire CAS column
cas_df['CAS'] = cas_df['CAS'].apply(get_first_cas)
cas_arr = cas_df['CAS'].tolist()

missing_df['CAS'] = missing_df['CAS'].apply(get_first_cas)
missing_arr = missing_df['CAS'].tolist()


def setup_webdriver():
    '''Initializes a headless selenium webdriver'''
    chrome_options = Options()
    chrome_options.add_argument("--headless")
    service = Service(ChromeDriverManager().install())
    driver = webdriver.Chrome(service=service, options=chrome_options)
    return driver

def url_inxight(cas):
    '''Generates an Inxight URL for a given CAS'''
    return f"https://drugs.ncats.io/substances?q={cas}"

# def url_inxight(cas):
#     '''Generates an Inxight URL for a given CAS'''
    return f"https://drugs.ncats.io/substances?q=%22{cas}%22&facet=Substance%20Form%2FPrincipal%20Form"


def get_inxight_url(molecule, driver):
    '''
    Parameters
    ----------
    A molecule's CAS and an initialised webdriver.

    Returns
    -------
    The top Inxight search result for a given CAS number
    '''
    
    url = "N/A"  # Default in case of failure

    driver.get(url_inxight(molecule))
    try:
        WebDriverWait(driver, 3).until(EC.visibility_of_element_located((By.CSS_SELECTOR, 'a[id="card-title"]')))
        elements = driver.find_elements(By.CSS_SELECTOR, 'a[id="card-title"]')
        if elements:
            element = elements[0]
            url = element.get_attribute('href')

    except (NoSuchElementException, TimeoutException):
        pass  

    return molecule, url

def get_best_urls(cas_arr):
    '''
    Parameters
    ----------
    An array of CAS values

    Returns
    -------
    An array of associated top matches
    '''
    
    best_matches = []
    driver = setup_webdriver()  
    try:
        for cas in cas_arr:
            molecule, url = get_inxight_url(cas, driver)
            best_matches.append((molecule, url))
    finally:
        driver.quit()  

    return best_matches


links = get_best_urls(cas_arr)


links


len(links)


identifiers = [url.split('/')[-1] for _, url in links]
identifiers = [identifier if identifier != 'A' else 'MISSING' for identifier in identifiers]
identifiers


# def extract_conditions_and_phases(data):
#     conditions_list = []
#     highest_approval_list = []

#     for entry in data:
#         if entry['name'] == 'Conditions' and 'value' in entry:
#             condition_info = entry['value']
            
#             # Extract the condition name
#             label = condition_info.get('label')
#             if label:
#                 conditions_list.append(label)
            
#             # Extract the highest phase of approval
#             highest_phase = condition_info.get('highestPhase')
#             if highest_phase:
#                 highest_approval_list.append(highest_phase)

#     return conditions_list, highest_approval_list

def extract_conditions_and_phases(data):
    """Extract conditions and their highest phases of approval from the API data."""
    conditions_list = []
    highest_approval_list = []

    for entry in data:
        if isinstance(entry, dict) and entry.get('name') == 'Conditions' and 'value' in entry:
            condition_info = entry['value']
            
            # Extract the condition name
            label = condition_info.get('label')
            if label:
                conditions_list.append(label)
            
            # Extract the highest phase of approval
            highest_phase = condition_info.get('highestPhase')
            if highest_phase:
                highest_approval_list.append(highest_phase)

    return conditions_list, highest_approval_list


def extract_event_details(data):
    event_details = {}
    
    for item in data:
        if 'value' in item and isinstance(item['value'], dict):  # Ensure 'value' is a dictionary
            details = item['value']
            if 'status' in details and 'sourceID' in details:
                if item['name'] == 'Highest Development Event' or item['name'] == 'Earliest Approved Event':
                    # Gather additional details
                    source_id = details.get('sourceID', 'No Source ID')
                    source_url = details.get('sourceURL', 'No Source URL')
                    
                    detail_info = {
                        'Status and Year': f"{details['status']} {details.get('year', '')}",
                        'Source ID': source_id,
                        'Source URL': source_url
                    }
                    
                    # Use the 'name' of the event as the key in the dictionary
                    event_details[item['name']] = detail_info
    
    return event_details


# def extract_events(identifiers):
#     events = []

#     for identifier in identifiers:
#         if identifier == "MISSING":
#             events.append({'Highest Development Event': {'Status and Year': 'Possibly Marketed Outside US 1996',
#    'Source ID': 'ANDA040166',
#    'Source URL': 'https://dailymed.nlm.nih.gov/dailymed/drugInfo.cfm?setid=c0ec47b7-c13a-4fa0-91fe-d7a03c70aec9'},
#   'Earliest Approved Event': {'Status and Year': 'Possibly Marketed Outside US 1996',
#    'Source ID': 'ANDA040166',
#    'Source URL': 'https://dailymed.nlm.nih.gov/dailymed/drugInfo.cfm?setid=c0ec47b7-c13a-4fa0-91fe-d7a03c70aec9'}})
#         data = get_additional_data(identifier)
#         print(extract_event_details(data))
#         events.append(extract_event_details(data))

#     return events
        
# events_arr = extract_events(identifiers)

def extract_events(identifiers):
    events = []
    acc = 0

    for identifier in identifiers:
        acc += 1
        print(acc)
        if identifier == "MISSING":
            # Create a dictionary where all details are 'MISSING'
            missing_details = {
                'Highest Development Event': {
                    'Status and Year': 'N/A',
                    'Source ID': 'N/A',
                    'Source URL': 'N/A'
                },
                'Earliest Approved Event': {
                    'Status and Year': 'N/A',
                    'Source ID': 'N/A',
                    'Source URL': 'N/A'
                }
            }
            events.append(missing_details)
        else:
            data = get_additional_data(identifier)
            event_details = extract_event_details(data)
            events.append(event_details)

    return events


def extract_conditions(identifiers):
    """Extract conditions for a list of identifiers."""
    conditions = []

    for identifier in identifiers:
        if identifier == "MISSING":
            conditions.append((['N/A'], ['N/A']))
        else:
            data = get_additional_data(identifier)
            if data:  # Check if data is not empty
                extracted_data = extract_conditions_and_phases(data)
                conditions.append(extracted_data)
            else:
                conditions.append(([], []))  # Append empty lists if no data
    return conditions


import requests

def get_additional_data(id):
    r = requests.get(f'https://drugs.ncats.io/api/v1/substances({id})/@additional')
    if 200 == r.status_code:
        return r.json()
    return '{}'


events_arr = extract_events(identifiers)
events_arr


import requests

def get_additional_data(id):
    r = requests.get(f'https://drugs.ncats.io/api/v1/substances({id})/@additional')
    if 200 == r.status_code:
        return r.json()
    return ([], [])


conditions_arr = extract_conditions(identifiers)
conditions_arr


data = []
for event in events_arr:
    record = {}
    for key, value in event.items():
        for sub_key, sub_value in value.items():
            record[f"{key} {sub_key}"] = sub_value
    data.append(record)

df = pd.DataFrame(data)


rows = [{'conditions': conditions, 'phases': phases} for conditions, phases in conditions_arr]

# Create DataFrame
conditions_df = pd.DataFrame(rows)
conditions_df['conditions'] = conditions_df['conditions'].apply(lambda x: '; '.join(x))
conditions_df['phases'] = conditions_df['phases'].apply(lambda x: '; '.join(x))
conditions_df


merged = pd.concat([df, conditions_df], axis=1)
merged


links_df = pd.DataFrame(links, columns=['CAS', 'URL'])
links_df


result = pd.concat([links_df, merged], axis=1)
result


result.tail(10)


result.to_csv("inxight_data_1.csv")



